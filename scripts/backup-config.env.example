# Knowledge Mapper Backup Configuration
# Copy to backup-config.env and customize for your environment
#
# Usage:
#   source scripts/backup-config.env && ./scripts/db-backup.sh
#   # Or set in your environment / systemd service / cron job

# =============================================================================
# Database Connection
# =============================================================================
# These can be inherited from your main .env file, but can be overridden here
# for backup-specific connection settings (e.g., connecting to a replica)

POSTGRES_HOST=localhost
POSTGRES_PORT=5435
POSTGRES_DB=knowledge_mapper_db
POSTGRES_USER=knowledge_mapper_user

# IMPORTANT: PGPASSWORD should be set securely, NOT in this file for production
# Options:
#   1. Export in environment: export PGPASSWORD=your_password
#   2. Use .pgpass file: ~/.pgpass (chmod 600)
#   3. Use systemd credential management
#   4. Use a secrets manager (HashiCorp Vault, AWS Secrets Manager, etc.)
# PGPASSWORD=

# =============================================================================
# Backup Storage (Local)
# =============================================================================
# Local backup directory - ensure adequate disk space
# Recommendation: Monitor disk usage and set up alerts

BACKUP_DIR=./backups

# =============================================================================
# Retention Policy
# =============================================================================
# Configure how long to keep backups of each type
# Adjust based on your compliance requirements and storage capacity

# Daily backups: Keep for 7 days (recent recovery)
BACKUP_RETENTION_DAILY=7

# Weekly backups: Keep for 4 weeks (point-in-time recovery)
BACKUP_RETENTION_WEEKLY=4

# Monthly backups: Keep for 12 months (compliance, long-term)
BACKUP_RETENTION_MONTHLY=12

# =============================================================================
# S3 Remote Storage (Optional)
# =============================================================================
# Configure S3-compatible storage for offsite backup copies
# Supports AWS S3, MinIO, Backblaze B2, Wasabi, etc.

# S3 bucket name (leave empty to disable S3 upload)
# BACKUP_S3_BUCKET=your-bucket-name

# S3 prefix/folder for organizing backups
# BACKUP_S3_PREFIX=backups/knowledge-mapper/

# S3-compatible endpoint URL (optional, for non-AWS S3)
# Examples:
#   MinIO:      http://minio:9000
#   Backblaze:  https://s3.us-west-002.backblazeb2.com
#   Wasabi:     https://s3.wasabisys.com
# BACKUP_S3_ENDPOINT=

# AWS credentials (if not using IAM roles or ~/.aws/credentials)
# In production, prefer IAM roles or instance profiles
# AWS_REGION=us-east-1
# AWS_ACCESS_KEY_ID=your-access-key
# AWS_SECRET_ACCESS_KEY=your-secret-key

# =============================================================================
# Example Configurations
# =============================================================================

# --- Local Development ---
# POSTGRES_HOST=localhost
# POSTGRES_PORT=5435
# BACKUP_DIR=./backups
# BACKUP_RETENTION_DAILY=3
# BACKUP_RETENTION_WEEKLY=2
# BACKUP_RETENTION_MONTHLY=1

# --- Docker Compose ---
# POSTGRES_HOST=postgres
# POSTGRES_PORT=5432
# BACKUP_DIR=/backups
# BACKUP_RETENTION_DAILY=7
# BACKUP_RETENTION_WEEKLY=4
# BACKUP_RETENTION_MONTHLY=12

# --- Production with S3 ---
# POSTGRES_HOST=prod-db.example.com
# POSTGRES_PORT=5432
# BACKUP_DIR=/var/backups/knowledge-mapper
# BACKUP_RETENTION_DAILY=7
# BACKUP_RETENTION_WEEKLY=4
# BACKUP_RETENTION_MONTHLY=12
# BACKUP_S3_BUCKET=mycompany-backups
# BACKUP_S3_PREFIX=databases/knowledge-mapper/
# AWS_REGION=us-east-1

# --- MinIO (Local S3-compatible) ---
# BACKUP_S3_BUCKET=backups
# BACKUP_S3_PREFIX=knowledge-mapper/
# BACKUP_S3_ENDPOINT=http://minio:9000
# AWS_ACCESS_KEY_ID=minioadmin
# AWS_SECRET_ACCESS_KEY=minioadmin

# =============================================================================
# Restore Configuration
# =============================================================================
# Settings for the db-restore.sh script

# Skip confirmation prompts (for automated/scripted restores)
# WARNING: Use with extreme caution - data loss is possible!
# RESTORE_SKIP_CONFIRM=false

# Create a backup of the current database before restoring
# Highly recommended to leave enabled for safety
RESTORE_PRE_BACKUP=true

# =============================================================================
# Cron Schedule Examples
# =============================================================================
# Add to crontab with: crontab -e
#
# Daily backup at 2 AM:
#   0 2 * * * cd /path/to/project && source .env && ./scripts/db-backup.sh --type=daily >> /var/log/backup.log 2>&1
#
# Weekly backup on Sunday at 3 AM:
#   0 3 * * 0 cd /path/to/project && source .env && ./scripts/db-backup.sh --type=weekly >> /var/log/backup.log 2>&1
#
# Monthly backup on 1st at 4 AM:
#   0 4 1 * * cd /path/to/project && source .env && ./scripts/db-backup.sh --type=monthly >> /var/log/backup.log 2>&1

# =============================================================================
# Restore Examples
# =============================================================================
#
# List available backups:
#   ./scripts/db-restore.sh --list
#
# Restore most recent backup:
#   export PGPASSWORD=your_password && ./scripts/db-restore.sh --latest
#
# Restore from S3:
#   export PGPASSWORD=your_password && ./scripts/db-restore.sh --from-s3 --latest
#
# Dry run (preview without restoring):
#   ./scripts/db-restore.sh --dry-run backup_file.sql.gz
#
# Restore schema only (no data):
#   export PGPASSWORD=your_password && ./scripts/db-restore.sh --schema-only backup_file.sql.gz
#
# Automated restore (no prompts - USE WITH CAUTION):
#   RESTORE_SKIP_CONFIRM=true ./scripts/db-restore.sh --latest
#
# Verify database after restore:
#   ./scripts/db-verify.sh
